{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7c6c8941-6393-46e3-a82e-6bfc1a698ba8",
   "metadata": {},
   "source": [
    "# Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22144207-f3bf-4404-ba25-fad3b4138dfd",
   "metadata": {},
   "source": [
    "## Lectura de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6eb81dc-bb2e-48f4-ade6-8e8c2928bc0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import gensim\n",
    "df = pd.read_pickle(\"./dataset/final.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04a308f1-8800-42f5-9fb4-ca686149a36b",
   "metadata": {},
   "source": [
    "## Total de palabras en el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8877383-fc48-4fa9-88d6-3981e83f6754",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_words = []\n",
    "unique_words = set()\n",
    "for document in df.clean:\n",
    "    for word in document:\n",
    "        list_of_words.append(word)\n",
    "        unique_words.add(word)\n",
    "        \n",
    "total_words = len(list_of_words)  # total words\n",
    "unique_words = len(unique_words)   # total unique words\n",
    "print(\"Total words:\" + str(total_words) + \" unique_words:\" + str(unique_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe49ee6-4337-4be6-885f-1d06828a4ba1",
   "metadata": {},
   "source": [
    "## División de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e42a9f-bea1-4a10-a93b-a188acf5cab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.clean_joined, df.isfake, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80732f7a-bea2-4096-a031-22fa0b3c828e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "\n",
    "tokenizer = Tokenizer(num_words = total_words)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_seq = tokenizer.texts_to_sequences(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "980ba4bf-d7fd-4038-8f05-e5fe13cea43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "x_train_padded = pad_sequences(x_train_seq, maxlen = 40, padding = 'post', truncating = 'post')\n",
    "x_test_padded = pad_sequences(x_test_seq, maxlen = 40, truncating = 'post') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac32411-cf77-41d5-9c52-448d6d799b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_seq[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0378675f-2aa6-4fae-96fc-6681181acaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x_train_padded[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ebd18c3-44a4-4d5a-a644-46c28d0c4aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "y_train = np.asarray(y_train).astype('float32').reshape((-1,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4f31c6e-f8b4-4c80-a559-ae931b0a5bdc",
   "metadata": {},
   "source": [
    "## Construcción del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246bf74e-de4d-438c-ad1b-5e78990402eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer=TfidfVectorizer(max_features=10000)\n",
    "x_train_padded=vectorizer.fit_transform(x_train_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509956d-1e61-48e5-b133-0963977eecd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_padded=vectorizer.fit_transform(x_test_padded)\n",
    "dense=x_train_padded.todense()\n",
    "dense_2=x_test_padded.todense()\n",
    "denselist=dense.tolist()\n",
    "denselist_2=dense_2.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5910571d-e43b-40ec-9ae0-20bc3ffa5b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_padded=da.from_array(x_train, chunks=(1000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88608c70-251e-4232-a516-b99c20b3a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(denselist, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864c1c52-cd2a-409d-a182-fff81ab3c11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=clf.predict(denselist_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5149a706-4519-4083-9254-d53a5abe9c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
